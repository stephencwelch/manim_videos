{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ec03ba-1d7b-4467-a6cd-2a2ef21b350d",
   "metadata": {},
   "source": [
    "## Hacking 3 - DeepSeek v3 with Random weights - more tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532be59a-3978-4b6b-8a3f-24001227e9cd",
   "metadata": {},
   "source": [
    "So, I think I can just start with hacking/tracing through the MLA class...but where do i find the hyperparams..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed57afa-b16c-4146-95d5-9882001595c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('DeepSeek-V3/inference') #Github slightly newer\n",
    "# sys.path.append('DeepSeek-V3/DeepSeek-V3/inference') #Hugging face\n",
    "\n",
    "from model import Transformer, MLA, ModelArgs, apply_rotary_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c67b717-6676-4c67-a652-bd18c2929e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c5f3056-0442-47ea-aa68-16386f134137",
   "metadata": {},
   "outputs": [],
   "source": [
    "args=ModelArgs(**{\"vocab_size\": 129280,\n",
    "                \"dim\": 7168,\n",
    "                \"inter_dim\": 18432,\n",
    "                \"moe_inter_dim\": 2048,\n",
    "                \"n_layers\": 61,\n",
    "                \"n_dense_layers\": 3,\n",
    "                \"n_heads\": 128,\n",
    "                \"n_routed_experts\": 256,\n",
    "                \"n_shared_experts\": 1,\n",
    "                \"n_activated_experts\": 8,\n",
    "                \"n_expert_groups\": 8,\n",
    "                \"n_limited_groups\": 4,\n",
    "                \"route_scale\": 2.5,\n",
    "                \"score_func\": \"sigmoid\",\n",
    "                \"q_lora_rank\": 1536,\n",
    "                \"kv_lora_rank\": 512,\n",
    "                \"qk_nope_head_dim\": 128,\n",
    "                \"qk_rope_head_dim\": 64,\n",
    "                \"v_head_dim\": 128,\n",
    "                \"dtype\": \"bf16\"}) #fp8 seems out due to my hardware? bf16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbd9dc96-cd0d-40b7-b19c-b6678727444e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelArgs(max_batch_size=8, max_seq_len=16384, dtype='bf16', vocab_size=129280, dim=7168, inter_dim=18432, moe_inter_dim=2048, n_layers=61, n_dense_layers=3, n_heads=128, n_routed_experts=256, n_shared_experts=1, n_activated_experts=8, n_expert_groups=8, n_limited_groups=4, score_func='sigmoid', route_scale=2.5, q_lora_rank=1536, kv_lora_rank=512, qk_nope_head_dim=128, qk_rope_head_dim=64, v_head_dim=128, original_seq_len=4096, rope_theta=10000.0, rope_factor=40, beta_fast=32, beta_slow=1, mscale=1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8bfeae6-d860-491f-946c-fa38a6ecc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mla=MLA(args)\n",
    "model=Transformer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aca7d10-ff1b-4fda-b916-57822ed85804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4023b41b-c655-4197-82f8-6b861c4daf82",
   "metadata": {},
   "source": [
    "Ok that's cool - can I get an actual text encoding and then embedding? That would be nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "900974f1-ecbd-498b-92fb-79567eb72375",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('/home/stephen/deepseek/DeepSeek-V3/DeepSeek-V3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "338871e3-f9cb-4cd1-a774-548a1515cc70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 671, 3707, 14364, 344, 4332, 14, 5403, 14, 305]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens=tokenizer.encode(\"The American flag is red, white, and\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d017e7f2-7542-4664-8ad5-868bb2e6a54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<｜begin▁of▁sentence｜>The American flag is red, white, and'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50aeadab-0286-43eb-917b-23da4aade1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7570f1ce-bfe4-426b-9c37-6d38cecd0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_prompt=model.embed(torch.tensor(tokenizer.encode(\"The American flag is red, white, and\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6df89d76-850e-4127-858a-979444433330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 7168])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_prompt.shape #Ok gussing that weight are just zeros right now or something??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f987ad8a-fd57-458b-8f5e-3edc7f347089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(torch.tensor([tokens]), start_pos=0) #Dope! Ran on CPU somehow - took a couple minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15076bdf-0985-469a-9649-5f3d23822dfb",
   "metadata": {},
   "source": [
    "- Ok, now how do I get into the first (or any really) MLA layer?\n",
    "- Maybe it's just like, can i grab or replicate the args?\n",
    "- Ideally without having to wait for forward each time?\n",
    "\n",
    "```\n",
    "def forward(self, x: torch.Tensor, start_pos: int, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5a2adc9-cec2-4a3f-87fd-f4ed07fae6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seqlen = tokens.size(1)\n",
    "seqlen = torch.tensor([tokens]).size(1)\n",
    "seqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a00989c8-ea30-45bb-8968-992a6a401524",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.embed(torch.tensor([tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59550e29-24ee-40c2-8689-9a00f9912f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.tensor([tokens]).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4429894f-dc8c-4626-8072-649b72f4eaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 7168])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d631d692-d0b1-41e8-a6e9-dffbd10ac5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_pos=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "020f4984-7cdc-4f5a-bc89-e761a619be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_cis = model.freqs_cis[start_pos:start_pos+seqlen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "640f2d3a-6ae4-4782-b37e-354a1fb8db87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_cis.shape #Love that this is complex, pretty cool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b0054c9-fb63-402b-86d7-751736faadef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = None\n",
    "if seqlen > 1:\n",
    "    mask = torch.full((seqlen, seqlen), float(\"-inf\"), device='cpu').triu_(1) #CPUing for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00cfadf4-fa2a-4a4b-bc00-2e4490fb77e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55e1c96d-662f-4692-99d4-c60975328b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out=model.layers[0].forward(h, start_pos, freqs_cis, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5afaccd-0d46-4564-aed7-febed472ca9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 7168])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8e30c95-7d3f-4273-b14e-32111db4da4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "295e1f82-af35-42d7-8e5d-09cc8a67bd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLA(\n",
       "  (wq_a): Linear()\n",
       "  (q_norm): RMSNorm()\n",
       "  (wq_b): ColumnParallelLinear()\n",
       "  (wkv_a): Linear()\n",
       "  (kv_norm): RMSNorm()\n",
       "  (wkv_b): ColumnParallelLinear()\n",
       "  (wo): RowParallelLinear()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69f0f7fa-ebed-47fc-836b-ef9cbb155774",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out=model.layers[0].attn.forward(h, start_pos, freqs_cis, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ecfd6a3-bf14-4871-a402-446919f3d6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 7168])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d3880-4974-4dd7-a941-49341916194c",
   "metadata": {},
   "source": [
    "- Ok, so there's my arguments - maybe I pickle them real quick to I can pick back up if needed?\n",
    "- From there I should be able to replicate/walk through the MLA forward pass, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce8b5472-ff9d-444f-bf22-4e82aae5f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Pickling\n",
    "# with open('mla_dummy_inputs.p', 'wb') as file:\n",
    "#     pickle.dump((h, start_pos, freqs_cis, mask), file)\n",
    "\n",
    "# # Unpickling\n",
    "# with open('mla_dummy_inputs.p', 'rb') as file:\n",
    "#     (h, start_pos, freqs_cis, mask) = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c64cef09-055c-4085-ae9f-d585b4e6c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out=model.layers[0].attn.forward(h, start_pos, freqs_cis, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2561bd4-633b-44f8-bc8c-bff2662ed019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 7168])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ce19f-676c-4a46-83f5-de0dd72937b1",
   "metadata": {},
   "source": [
    "- ok ok ok ok I think it's probably worth spending a little time understanding what's going on in `__init__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8eecbce0-e137-42e1-bda7-acc5800e93f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7168"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0d7be18-da31-4dca-8cda-328229db97c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8a30370-6e26-41c4-bfea-fb4ac77f019a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.n_local_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14d90ad6-ba04-4607-8b9a-61c5766f9f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.q_lora_rank #q_lora_rank (int): Rank for low-rank query projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2059cdb6-6fa9-4ee8-ade9-570d4a920c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.kv_lora_rank #Rank for low-rank key/value projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b4b41c9-ce05-4c9c-8906-69de6f3176f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.qk_nope_head_dim #Dimensionality of non-positional query/key projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97bd77a0-76e6-4ad8-87e3-d66d76c57d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.qk_rope_head_dim #(int): Dimensionality of rotary-positional query/key projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9280e8c-69e5-44ef-a342-85a6897a239c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.v_head_dim #(int): Dimensionality of value projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e50918e-2971-4a71-86e6-e5699501e7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1352337788608801"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.softmax_scale #(float): Scaling factor for softmax in attention computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b81432e-21ad-4401-988c-c20a511d7525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.qk_head_dim #(int): Total dimensionality of query/key projections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4899cb-fbee-4469-a888-6f75dc29d652",
   "metadata": {},
   "source": [
    "```\n",
    "if self.q_lora_rank == 0:\n",
    "    self.wq = ColumnParallelLinear(self.dim, self.n_heads * self.qk_head_dim)\n",
    "else:\n",
    "    self.wq_a = Linear(self.dim, self.q_lora_rank)\n",
    "    self.q_norm = RMSNorm(self.q_lora_rank)\n",
    "    self.wq_b = ColumnParallelLinear(self.q_lora_rank, self.n_heads * self.qk_head_dim)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93a65328-8650-4e1a-bf3c-ebe670a64a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536, 7168])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.wq_a.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f86cfd7b-b9e7-4737-8938-b194fe0e47b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24576, 1536])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.wq_b.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01504456-ab97-4a4c-9e02-4cd6e482b578",
   "metadata": {},
   "source": [
    "```\n",
    "        self.wkv_a = Linear(self.dim, self.kv_lora_rank + self.qk_rope_head_dim)\n",
    "        self.kv_norm = RMSNorm(self.kv_lora_rank)\n",
    "        self.wkv_b = ColumnParallelLinear(self.kv_lora_rank, self.n_heads * (self.qk_nope_head_dim + self.v_head_dim))\n",
    "        self.wo = RowParallelLinear(self.n_heads * self.v_head_dim, self.dim)\n",
    "        self.softmax_scale = self.qk_head_dim ** -0.5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78625c81-15f7-4973-bf15-e6731e800bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([576, 7168])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.wkv_a.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "125242f7-1cbb-40d7-84ab-42bf4272f404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 512])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.wkv_b.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25e523e9-c64e-43c3-aea2-0e2495025346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7168, 16384])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.wo.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1b36b-d06d-4873-974c-4c6d607ae944",
   "metadata": {},
   "source": [
    "```\n",
    "if attn_impl == \"naive\":\n",
    "            self.register_buffer(\"k_cache\", torch.zeros(args.max_batch_size, args.max_seq_len, self.n_local_heads, self.qk_head_dim), persistent=False)\n",
    "            self.register_buffer(\"v_cache\", torch.zeros(args.max_batch_size, args.max_seq_len, self.n_local_heads, self.v_head_dim), persistent=False)\n",
    "        else:\n",
    "            self.register_buffer(\"kv_cache\", torch.zeros(args.max_batch_size, args.max_seq_len, self.kv_lora_rank), persistent=False)\n",
    "            self.register_buffer(\"pe_cache\", torch.zeros(args.max_batch_size, args.max_seq_len, self.qk_rope_head_dim), persistent=False)\n",
    "            ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8ccedd8-331c-4b16-a4ee-f2b6137d6213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.register_buffer of MLA(\n",
       "  (wq_a): Linear()\n",
       "  (q_norm): RMSNorm()\n",
       "  (wq_b): ColumnParallelLinear()\n",
       "  (wkv_a): Linear()\n",
       "  (kv_norm): RMSNorm()\n",
       "  (wkv_b): ColumnParallelLinear()\n",
       "  (wo): RowParallelLinear()\n",
       ")>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.register_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb12cc6-1fa3-4436-b3ca-4a40ec0938da",
   "metadata": {},
   "source": [
    "```\n",
    "register_buffer in PyTorch is a method used to add a tensor to a module that should not be considered a model parameter. This means that while the tensor will be saved and loaded with the model's state dictionary and moved to the correct device, it will not be updated by the optimizer during training. It is typically used for tensors that are part of the model's state but are not learned parameters.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76ed521-dec6-4669-9f8f-ed40e8994c68",
   "metadata": {},
   "source": [
    "Cache size for naive key value caching:\n",
    "```\n",
    "args.max_batch_size, args.max_seq_len, self.n_local_heads, self.qk_head_dim\n",
    "args.max_batch_size, args.max_seq_len, self.n_local_heads, self.v_head_dim\n",
    "```\n",
    "\n",
    "For for MLA: \n",
    "```\n",
    "args.max_batch_size, args.max_seq_len, self.kv_lora_rank\n",
    "args.max_batch_size, args.max_seq_len, self.qk_rope_head_dim\n",
    "```\n",
    "\n",
    "Ok wow yeah cools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f9680c6-5f0e-4941-ac0e-12d4b6184b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16384, 512])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.kv_cache.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f0f33b0-64f1-4949-9cf9-65ff7f2c84e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16384, 64])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.pe_cache.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33a846-803b-45b1-8e4a-ac68765d40f5",
   "metadata": {},
   "source": [
    "Ok, now forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8587394-ef5e-40e4-adcf-3e90452c97c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out=model.layers[0].attn.forward(h, start_pos, freqs_cis, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9654782d-51ae-4e6c-85cf-9ee1146f03b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=h\n",
    "mla=model.layers[0].attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea891d0f-2dc9-46fe-946a-ca7458e7211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hay\n"
     ]
    }
   ],
   "source": [
    "bsz, seqlen, _ = x.size()\n",
    "end_pos = start_pos + seqlen\n",
    "if mla.q_lora_rank == 0:\n",
    "    q = self.wq(x)\n",
    "else:\n",
    "    q = mla.wq_b(mla.q_norm(mla.wq_a(x)))\n",
    "    print('hay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "963b9307-d8a9-4634-8184-1cbba066a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1=mla.wq_a(x)\n",
    "h2=mla.q_norm(mla.wq_a(x))\n",
    "q=mla.wq_b(mla.q_norm(mla.wq_a(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59fe02f0-0545-49eb-9b4c-d10c5a6ea3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 7168]),\n",
       " torch.Size([1, 10, 1536]),\n",
       " torch.Size([1, 10, 1536]),\n",
       " torch.Size([1, 10, 24576]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, h1.shape, h2.shape, q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21b2f4f-76c7-4c78-b26e-7c001b8bb224",
   "metadata": {},
   "source": [
    "- Ok so those are the queries for all the heads? I guess I didn't realize, or maybe I did that they were also doing query compression? How important is this? I guess it's less compute than going straight to 7168x24576..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d3a52a5-595c-4b33-b90b-8e9028b6c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = q.view(bsz, seqlen, mla.n_local_heads, mla.qk_head_dim) #Ok splitting out the queries across all the heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7aa17bc-76f3-4be0-a0e6-f1d6c6f91cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 128, 192])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0272cdc9-b4eb-4375-bbe4-087f6910c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_nope, q_pe = torch.split(q, [mla.qk_nope_head_dim, mla.qk_rope_head_dim], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09059116-e3f0-4e6e-824d-3a47ed925281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 128, 128]), torch.Size([1, 10, 128, 64]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_nope.shape, q_pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8aaa8bfd-f84d-4893-9d56-d2ab0b0ab9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_pe = apply_rotary_emb(q_pe, freqs_cis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a92c3c07-2b36-4a2b-81c7-2463fa75a517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 128, 64])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_pe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "577e0010-e938-4003-b5dd-00fd0968b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv = mla.wkv_a(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f79f3000-c5da-4dc6-aed1-705b0a7f62b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 576])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc37b8ee-d447-41c1-886c-80f39e14d748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 7168])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775922f6-dce6-49b6-9475-d9235bc48a19",
   "metadata": {},
   "source": [
    "That's a lot of squishing! No wonder it saves so much memory bandiwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4bb6e85-0e81-4e01-b42f-074eb7a62049",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv, k_pe = torch.split(kv, [mla.kv_lora_rank, mla.qk_rope_head_dim], dim=-1)\n",
    "k_pe = apply_rotary_emb(k_pe.unsqueeze(2), freqs_cis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d0c94b3-6d36-459c-b58f-cf5c3cbeb3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 512]), torch.Size([1, 10, 1, 64]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv.shape, k_pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc22283-86a8-4188-9456-97986fa54f89",
   "metadata": {},
   "source": [
    "- Ok cool cool so we're left with this last big lift, probably will be worth understanding the naive option:\n",
    "\n",
    "```\n",
    "        if attn_impl == \"naive\":\n",
    "            q = torch.cat([q_nope, q_pe], dim=-1)\n",
    "            kv = self.wkv_b(self.kv_norm(kv))\n",
    "            kv = kv.view(bsz, seqlen, self.n_local_heads, self.qk_nope_head_dim + self.v_head_dim)\n",
    "            k_nope, v = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1)\n",
    "            k = torch.cat([k_nope, k_pe.expand(-1, -1, self.n_local_heads, -1)], dim=-1)\n",
    "            self.k_cache[:bsz, start_pos:end_pos] = k\n",
    "            self.v_cache[:bsz, start_pos:end_pos] = v\n",
    "            scores = torch.einsum(\"bshd,bthd->bsht\", q, self.k_cache[:bsz, :end_pos]) * self.softmax_scale\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a7f58-8ef3-4da9-af6d-e0e179d1ff7a",
   "metadata": {},
   "source": [
    "- Main focus if of course the latent option\n",
    "\n",
    "```\n",
    "        else:\n",
    "            wkv_b = self.wkv_b.weight if self.wkv_b.scale is None else weight_dequant(self.wkv_b.weight, self.wkv_b.scale, block_size) \n",
    "            wkv_b = wkv_b.view(self.n_local_heads, -1, self.kv_lora_rank)\n",
    "            q_nope = torch.einsum(\"bshd,hdc->bshc\", q_nope, wkv_b[:, :self.qk_nope_head_dim])\n",
    "            self.kv_cache[:bsz, start_pos:end_pos] = self.kv_norm(kv)\n",
    "            self.pe_cache[:bsz, start_pos:end_pos] = k_pe.squeeze(2)\n",
    "            scores = (torch.einsum(\"bshc,btc->bsht\", q_nope, self.kv_cache[:bsz, :end_pos]) +\n",
    "                      torch.einsum(\"bshr,btr->bsht\", q_pe, self.pe_cache[:bsz, :end_pos])) * self.softmax_scale\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ba8f9e2-a0e5-4010-a562-c53724081835",
   "metadata": {},
   "outputs": [],
   "source": [
    "wkv_b = mla.wkv_b.weight if mla.wkv_b.scale is None else weight_dequant(mla.wkv_b.weight, mla.wkv_b.scale, block_size) \n",
    "wkv_b = wkv_b.view(mla.n_local_heads, -1, mla.kv_lora_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e29747d6-9fdb-4b03-92e2-afad044a9151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 256, 512])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wkv_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9b31ac06-f720-403b-a6f0-89456c81b03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 128, 512])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_nope = torch.einsum(\"bshd,hdc->bshc\", q_nope, wkv_b[:, :mla.qk_nope_head_dim])\n",
    "q_nope.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14079055-c679-477e-a6b4-db0f33bf84ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mla.kv_cache[:bsz, start_pos:end_pos] = mla.kv_norm(kv)\n",
    "mla.pe_cache[:bsz, start_pos:end_pos] = k_pe.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74fec2b1-f77d-446b-b476-171c78fa26b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = (torch.einsum(\"bshc,btc->bsht\", q_nope, mla.kv_cache[:bsz, :end_pos].to(torch.bfloat16)) +\n",
    "          torch.einsum(\"bshr,btr->bsht\", q_pe, mla.pe_cache[:bsz, :end_pos].to(torch.bfloat16))) * mla.softmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4cc042c6-aefc-4cfc-8a94-f2e07231eb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 128, 10])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb8bb4-e071-4376-9630-d6f2d89a76a3",
   "metadata": {},
   "source": [
    "- Hmm thought that would be then attention pattern? I guess maybe it is?\n",
    "- In my head it was square and like keys by queries? Hmm is it tokens be queries? Need to think about that a little."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f76a3514-e011-4876-b175-1ec85c448912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.bfloat16,\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0, :, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb4e81d3-23ba-4165-a764-96647dbd87c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3730c54-b2a5-44c2-9f01-b28ef02e4c4c",
   "metadata": {},
   "source": [
    "Ah ok right it's 128 10x10 attention patterns -> that could be kinda nice to visaulize! Maybe the mech in interp stuff could be good to review quickly - we'll where writing leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "995ac2f1-8dba-4f60-a3e9-8a86822e8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mask is not None:\n",
    "    scores += mask.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2db1e247-a8be-4c96-a876-ffb48281134b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.bfloat16,\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0, :, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e712d78-8e6d-4cd2-8649-524b0d17baf7",
   "metadata": {},
   "source": [
    "Yep cools. So attention patterns are tokens by tokens -> i guess wht makes sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2d2ef692-9d2c-46a9-ab4c-6845665bf0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = scores.softmax(dim=-1, dtype=torch.float32).type_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "214dbd02-1432-4ec7-bfc6-c76560acf317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000,\n",
       "         0.0000],\n",
       "        [0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111,\n",
       "         0.0000],\n",
       "        [0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
       "         0.1000]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0, :, 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf465307-b71b-4dd9-aa89-4809d237089f",
   "metadata": {},
   "source": [
    "I do feel like all zero weights makes this kinda tricky. Maybe I can switch to random at least - that shouldn't be bad actually right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f23bfc6c-ff40-4ece-8e8c-ea71df5bfd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.einsum(\"bsht,btc->bshc\", scores, mla.kv_cache[:bsz, :end_pos]) # On that's intresting - just the cache and attention pattern here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "16d48941-24a1-4b34-a464-cf919aaf5ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 128, 512])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9062040f-8c48-4ccd-be82-82d1f905167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.einsum(\"bshc,hdc->bshd\", x.to(torch.bfloat16), wkv_b[:, -mla.v_head_dim:]) #Not sure what this one is doing exactly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "610f642d-9907-456b-940c-519eaaf56e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 128, 128])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ef10174f-d2e6-451f-8314-c327c8052dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 16384])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.flatten(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "844718ab-c4a9-43a8-985d-2d2a4c633cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = mla.wo(x.flatten(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cc267eeb-1bae-439e-bff1-07d5ea47d8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 7168])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f770d323-5997-4a49-a19a-f8b25140d16c",
   "metadata": {},
   "source": [
    "And that's it. Ok I don't understand everything yet, but it doesn't seem so bad, and it runs! This is great. Back to writing next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1709e5-7625-43d3-bcce-a78df0ca8a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee77445-932f-438d-9af3-f435f7c12202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f9e2a0a6-6345-489a-a662-d34f802f7486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 128, 192])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape #There are the queries for all the heads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576b748-66cb-46fc-be82-c9d20142531a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e6059f-9790-48e1-8b20-0c22a5275a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf8623-070e-4145-bcbe-66a674647248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620cafe-83fb-479c-9866-e18425ebe847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa565d31-8bd5-493e-9862-10754ffc97af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67299a4c-1abc-4e8b-a138-e31f8cb5ffaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d702e3-5f09-4148-bbdf-a803d0d21450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f469d-8603-4c40-ab21-fc2d5930efe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc222042-6536-4363-aea5-4726fc41c8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cb327fe5-2839-4935-88ef-56dc3309c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b5532600-a5db-4d29-b571-95093c3586a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embed): ParallelEmbedding()\n",
       "  (layers): ModuleList(\n",
       "    (0-2): 3 x Block(\n",
       "      (attn): MLA(\n",
       "        (wq_a): Linear()\n",
       "        (q_norm): RMSNorm()\n",
       "        (wq_b): ColumnParallelLinear()\n",
       "        (wkv_a): Linear()\n",
       "        (kv_norm): RMSNorm()\n",
       "        (wkv_b): ColumnParallelLinear()\n",
       "        (wo): RowParallelLinear()\n",
       "      )\n",
       "      (ffn): MLP(\n",
       "        (w1): ColumnParallelLinear()\n",
       "        (w2): RowParallelLinear()\n",
       "        (w3): ColumnParallelLinear()\n",
       "      )\n",
       "      (attn_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "    )\n",
       "    (3-60): 58 x Block(\n",
       "      (attn): MLA(\n",
       "        (wq_a): Linear()\n",
       "        (q_norm): RMSNorm()\n",
       "        (wq_b): ColumnParallelLinear()\n",
       "        (wkv_a): Linear()\n",
       "        (kv_norm): RMSNorm()\n",
       "        (wkv_b): ColumnParallelLinear()\n",
       "        (wo): RowParallelLinear()\n",
       "      )\n",
       "      (ffn): MoE(\n",
       "        (gate): Gate()\n",
       "        (experts): ModuleList(\n",
       "          (0-255): 256 x Expert(\n",
       "            (w1): Linear()\n",
       "            (w2): Linear()\n",
       "            (w3): Linear()\n",
       "          )\n",
       "        )\n",
       "        (shared_experts): MLP(\n",
       "          (w1): ColumnParallelLinear()\n",
       "          (w2): RowParallelLinear()\n",
       "          (w3): ColumnParallelLinear()\n",
       "        )\n",
       "      )\n",
       "      (attn_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (head): ColumnParallelLinear()\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe24d53-41ef-4c2e-8cee-e8ec3453847d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894499f6-9607-4cdb-a7bb-46cb4340ee6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e99604-27cd-4b85-8bef-c56bd8cd2615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e31802-64b8-4774-9ca0-0c41c05524a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18d74eaa-9abf-4564-bdc4-c107dc883de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab36798e-e7ad-4016-ac4e-ef9a3c5037ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "360923fa-2e0a-4066-9a0a-460786c0ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mla(embedded_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c0986-e60f-4686-a9c8-4bb5b5cd4621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54812049-b9df-4d88-be79-e9391cd65b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ac8e4-b15d-41d3-9eb1-e3aa0e2590f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aaa6a3-742d-459f-9bdf-dafcc7d998e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb9405-b383-4686-9ea2-c50aebaf7177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e5bf63-bb0f-43a0-970c-4d5c4b2bdba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c386e49-e3cd-4981-af04-8baa0135787a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3118526-0265-4320-98cc-e3c8ebdc2dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66eaa3-3e65-4e6d-a309-f39830f44f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5aaee39d-2d1c-4bbf-93fb-3572f801c81d",
   "metadata": {},
   "source": [
    "```\n",
    "Big model:\n",
    "{\n",
    "    \"vocab_size\": 129280,\n",
    "    \"dim\": 7168,\n",
    "    \"inter_dim\": 18432,\n",
    "    \"moe_inter_dim\": 2048,\n",
    "    \"n_layers\": 61,\n",
    "    \"n_dense_layers\": 3,\n",
    "    \"n_heads\": 128,\n",
    "    \"n_routed_experts\": 256,\n",
    "    \"n_shared_experts\": 1,\n",
    "    \"n_activated_experts\": 8,\n",
    "    \"n_expert_groups\": 8,\n",
    "    \"n_limited_groups\": 4,\n",
    "    \"route_scale\": 2.5,\n",
    "    \"score_func\": \"sigmoid\",\n",
    "    \"q_lora_rank\": 1536,\n",
    "    \"kv_lora_rank\": 512,\n",
    "    \"qk_nope_head_dim\": 128,\n",
    "    \"qk_rope_head_dim\": 64,\n",
    "    \"v_head_dim\": 128,\n",
    "    \"dtype\": \"fp8\"\n",
    "}\n",
    "\n",
    "16B Model\n",
    "{\n",
    "    \"vocab_size\": 102400,\n",
    "    \"dim\": 2048,\n",
    "    \"inter_dim\": 10944,\n",
    "    \"moe_inter_dim\": 1408,\n",
    "    \"n_layers\": 27,\n",
    "    \"n_dense_layers\": 1,\n",
    "    \"n_heads\": 16,\n",
    "    \"n_routed_experts\": 64,\n",
    "    \"n_shared_experts\": 2,\n",
    "    \"n_activated_experts\": 6,\n",
    "    \"route_scale\": 1.0,\n",
    "    \"q_lora_rank\": 0,\n",
    "    \"kv_lora_rank\": 512,\n",
    "    \"qk_nope_head_dim\": 128,\n",
    "    \"qk_rope_head_dim\": 64,\n",
    "    \"v_head_dim\": 128,\n",
    "    \"mscale\": 0.707\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ae8a1-812f-42e2-96d9-790792e995fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b9325-c76f-4946-9a46-16de9c095a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b280c45-ea89-4c13-9804-f6c83825adf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556b10a5-bc70-48c8-9e38-483baa30fdfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
