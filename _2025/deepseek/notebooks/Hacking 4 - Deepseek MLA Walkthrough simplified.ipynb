{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5270c091-dc26-4a9b-beb6-9507ed08330d",
   "metadata": {},
   "source": [
    "## Hacking 4 - Deepseek MLA Walkthrough simplified\n",
    "- Ignore setup and naive method right now, got back to these as needed\n",
    "- Here just focus on understanding what's happening with the MLA forward pass.\n",
    "- Oh wow looks like it might kinda be possible to just load a subset of data from the safetensors?!\n",
    "- Hmm that's pretty interesting - distraction or a good use of time? Let me poke at it for a couplte minutes here.\n",
    "- If i wanted all the layer6 atention stuff, it looks like I would just need\n",
    "\n",
    "```\n",
    "\"model.layers.6.self_attn.q_a_proj.weight\": \"model-00009-of-000163.safetensors\"\n",
    "```\n",
    "\n",
    "And layer 0 attention stuff would just be: \n",
    "\n",
    "```\n",
    "\"model.layers.0.self_attn.q_a_proj.weight\": \"model-00001-of-000163.safetensors\"\n",
    "```\n",
    "- Ok I have a theory about why I can't load weights -> I bet it's because the hf and github repos -> eh that doesn't seem to be it. \n",
    "- Tried manually mapping too -> ran into size issues.\n",
    "- Ok let me push a little further here and try a \"clean start\" from the hf repo\"\n",
    "- Ok yeah I think the step i've been missing is \"convert.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fb9aac-9483-49fc-b3ac-fe13bf6558bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5236d095-f266-48cd-93d5-4c8dc34cd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "# sys.path.append('DeepSeek-V3/inference') #Github slightly newer\n",
    "sys.path.append('DeepSeek-V3/DeepSeek-V3/inference') #Hugging face\n",
    "\n",
    "from model import Transformer, MLA, ModelArgs, apply_rotary_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b578d74-1d47-486c-9090-af0509e87109",
   "metadata": {},
   "outputs": [],
   "source": [
    "args=ModelArgs(**{\"vocab_size\": 129280,\n",
    "                \"dim\": 7168,\n",
    "                \"inter_dim\": 18432,\n",
    "                \"moe_inter_dim\": 2048,\n",
    "                \"n_layers\": 61,\n",
    "                \"n_dense_layers\": 3,\n",
    "                \"n_heads\": 128,\n",
    "                \"n_routed_experts\": 256,\n",
    "                \"n_shared_experts\": 1,\n",
    "                \"n_activated_experts\": 8,\n",
    "                \"n_expert_groups\": 8,\n",
    "                \"n_limited_groups\": 4,\n",
    "                \"route_scale\": 2.5,\n",
    "                \"score_func\": \"sigmoid\",\n",
    "                \"q_lora_rank\": 1536,\n",
    "                \"kv_lora_rank\": 512,\n",
    "                \"qk_nope_head_dim\": 128,\n",
    "                \"qk_rope_head_dim\": 64,\n",
    "                \"v_head_dim\": 128,\n",
    "                \"dtype\": \"bf16\"}) #fp8 seems out due to my hardware? bf16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e12263-0066-4fc5-a60c-1b9d02ab4133",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Transformer(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba61d41-d29a-4c8f-b557-ccae1025d621",
   "metadata": {},
   "source": [
    "### Let me spend a few minutes seeing if I can load just the attention weights for the embedding, layers 0 and maybe layer 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "280ef79f-b250-481a-87e9-f40890cf5c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_model, load_file\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2665483c-446d-4b28-9865-160c41787d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ckpt_path='/home/stephen/deepseek/DeepSeek-V3/DeepSeek-V3'\n",
    "ckpt_path='/home/stephen/deepseek/clean_hf_pull/DeepSeek-V3/weights_converted'\n",
    "# rank=0\n",
    "# world_size=1\n",
    "\n",
    "#\n",
    "# missing, unexpected=load_model(model, os.path.join(ckpt_path, 'model-00001-of-000163.safetensors'), strict=False)\n",
    "# load_model(model, os.path.join(ckpt_path, 'model-00009-of-000163.safetensors'), strict=False)\n",
    "missing, unexpected=load_model(model, os.path.join(ckpt_path, \"model0-mp1.safetensors\"), strict=False) #Result of conversion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e3db20d-6bff-40ad-a9e8-c1364c2e60aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44960"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59601d3c-2449-441d-823a-0828152ab13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unexpected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82a912e4-388d-46f5-b397-3c817f5648a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = load_file(os.path.join(ckpt_path, \"model0-mp1.safetensors\"), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8456c9b5-2af6-4ec2-81cf-3c6ccbb92231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['embed.weight', 'layers.0.attn.kv_norm.weight', 'layers.0.attn.q_norm.weight', 'layers.0.attn.wkv_a.scale', 'layers.0.attn.wkv_a.weight', 'layers.0.attn.wkv_b.scale', 'layers.0.attn.wkv_b.weight', 'layers.0.attn.wo.scale', 'layers.0.attn.wo.weight', 'layers.0.attn.wq_a.scale', 'layers.0.attn.wq_a.weight', 'layers.0.attn.wq_b.scale', 'layers.0.attn.wq_b.weight', 'layers.0.attn_norm.weight', 'layers.0.ffn.w1.scale', 'layers.0.ffn.w1.weight', 'layers.0.ffn.w2.scale', 'layers.0.ffn.w2.weight', 'layers.0.ffn.w3.scale', 'layers.0.ffn.w3.weight', 'layers.0.ffn_norm.weight', 'layers.1.attn.kv_norm.weight', 'layers.1.attn.q_norm.weight', 'layers.1.attn.wkv_a.scale', 'layers.1.attn.wkv_a.weight', 'layers.1.attn.wkv_b.scale', 'layers.1.attn.wkv_b.weight', 'layers.1.attn.wo.scale', 'layers.1.attn.wo.weight', 'layers.1.attn.wq_a.scale', 'layers.1.attn.wq_a.weight', 'layers.1.attn.wq_b.scale', 'layers.1.attn.wq_b.weight', 'layers.1.attn_norm.weight', 'layers.1.ffn.w1.scale', 'layers.1.ffn.w1.weight', 'layers.1.ffn.w2.scale', 'layers.1.ffn.w2.weight', 'layers.1.ffn.w3.scale', 'layers.1.ffn.w3.weight', 'layers.1.ffn_norm.weight', 'layers.2.attn.kv_norm.weight', 'layers.2.attn.q_norm.weight', 'layers.2.attn.wkv_a.scale', 'layers.2.attn.wkv_a.weight', 'layers.2.attn.wkv_b.scale', 'layers.2.attn.wkv_b.weight', 'layers.2.attn.wo.scale', 'layers.2.attn.wo.weight', 'layers.2.attn.wq_a.scale', 'layers.2.attn.wq_a.weight', 'layers.2.attn.wq_b.scale', 'layers.2.attn.wq_b.weight', 'layers.2.attn_norm.weight', 'layers.2.ffn.w1.scale', 'layers.2.ffn.w1.weight', 'layers.2.ffn.w2.scale', 'layers.2.ffn.w2.weight', 'layers.2.ffn.w3.scale', 'layers.2.ffn.w3.weight', 'layers.2.ffn_norm.weight', 'layers.3.attn.kv_norm.weight', 'layers.3.attn.q_norm.weight', 'layers.3.attn.wkv_a.scale', 'layers.3.attn.wkv_a.weight', 'layers.3.attn.wkv_b.scale', 'layers.3.attn.wkv_b.weight', 'layers.3.attn.wo.scale', 'layers.3.attn.wo.weight', 'layers.3.attn.wq_a.scale', 'layers.3.attn.wq_a.weight', 'layers.3.attn.wq_b.scale', 'layers.3.attn.wq_b.weight', 'layers.3.ffn.experts.0.w1.scale', 'layers.3.ffn.experts.0.w1.weight', 'layers.3.ffn.experts.0.w2.scale', 'layers.3.ffn.experts.0.w2.weight', 'layers.3.ffn.experts.0.w3.scale', 'layers.3.ffn.experts.0.w3.weight', 'layers.3.ffn.experts.1.w1.scale', 'layers.3.ffn.experts.1.w1.weight', 'layers.3.ffn.experts.1.w2.scale', 'layers.3.ffn.experts.1.w2.weight', 'layers.3.ffn.experts.1.w3.scale', 'layers.3.ffn.experts.1.w3.weight', 'layers.3.ffn.experts.10.w1.scale', 'layers.3.ffn.experts.10.w1.weight', 'layers.3.ffn.experts.10.w2.scale', 'layers.3.ffn.experts.10.w2.weight', 'layers.3.ffn.experts.10.w3.scale', 'layers.3.ffn.experts.10.w3.weight', 'layers.3.ffn.experts.11.w1.scale', 'layers.3.ffn.experts.11.w1.weight', 'layers.3.ffn.experts.11.w2.scale', 'layers.3.ffn.experts.11.w2.weight', 'layers.3.ffn.experts.11.w3.scale', 'layers.3.ffn.experts.11.w3.weight', 'layers.3.ffn.experts.12.w1.scale', 'layers.3.ffn.experts.12.w1.weight', 'layers.3.ffn.experts.12.w2.scale', 'layers.3.ffn.experts.12.w2.weight', 'layers.3.ffn.experts.12.w3.scale', 'layers.3.ffn.experts.12.w3.weight', 'layers.3.ffn.experts.13.w1.scale', 'layers.3.ffn.experts.13.w1.weight', 'layers.3.ffn.experts.13.w2.scale', 'layers.3.ffn.experts.13.w2.weight', 'layers.3.ffn.experts.13.w3.scale', 'layers.3.ffn.experts.13.w3.weight', 'layers.3.ffn.experts.14.w1.scale', 'layers.3.ffn.experts.14.w1.weight', 'layers.3.ffn.experts.14.w2.scale', 'layers.3.ffn.experts.14.w2.weight', 'layers.3.ffn.experts.14.w3.scale', 'layers.3.ffn.experts.14.w3.weight', 'layers.3.ffn.experts.15.w1.scale', 'layers.3.ffn.experts.15.w1.weight', 'layers.3.ffn.experts.15.w2.scale', 'layers.3.ffn.experts.15.w2.weight', 'layers.3.ffn.experts.15.w3.scale', 'layers.3.ffn.experts.15.w3.weight', 'layers.3.ffn.experts.16.w1.scale', 'layers.3.ffn.experts.16.w1.weight', 'layers.3.ffn.experts.16.w2.scale', 'layers.3.ffn.experts.16.w2.weight', 'layers.3.ffn.experts.16.w3.scale', 'layers.3.ffn.experts.16.w3.weight', 'layers.3.ffn.experts.17.w1.scale', 'layers.3.ffn.experts.17.w1.weight', 'layers.3.ffn.experts.17.w2.scale', 'layers.3.ffn.experts.17.w2.weight', 'layers.3.ffn.experts.17.w3.scale', 'layers.3.ffn.experts.17.w3.weight', 'layers.3.ffn.experts.18.w1.scale', 'layers.3.ffn.experts.18.w1.weight', 'layers.3.ffn.experts.18.w2.scale', 'layers.3.ffn.experts.18.w2.weight', 'layers.3.ffn.experts.18.w3.scale', 'layers.3.ffn.experts.18.w3.weight', 'layers.3.ffn.experts.19.w1.scale', 'layers.3.ffn.experts.19.w1.weight', 'layers.3.ffn.experts.19.w2.scale', 'layers.3.ffn.experts.19.w2.weight', 'layers.3.ffn.experts.19.w3.scale', 'layers.3.ffn.experts.19.w3.weight', 'layers.3.ffn.experts.2.w1.scale', 'layers.3.ffn.experts.2.w1.weight', 'layers.3.ffn.experts.2.w2.scale', 'layers.3.ffn.experts.2.w2.weight', 'layers.3.ffn.experts.2.w3.scale', 'layers.3.ffn.experts.2.w3.weight', 'layers.3.ffn.experts.20.w1.scale', 'layers.3.ffn.experts.20.w1.weight', 'layers.3.ffn.experts.20.w2.scale', 'layers.3.ffn.experts.20.w2.weight', 'layers.3.ffn.experts.20.w3.scale', 'layers.3.ffn.experts.20.w3.weight', 'layers.3.ffn.experts.21.w1.scale', 'layers.3.ffn.experts.21.w1.weight', 'layers.3.ffn.experts.21.w2.scale', 'layers.3.ffn.experts.21.w2.weight', 'layers.3.ffn.experts.21.w3.scale', 'layers.3.ffn.experts.21.w3.weight', 'layers.3.ffn.experts.22.w1.scale', 'layers.3.ffn.experts.22.w1.weight', 'layers.3.ffn.experts.22.w2.scale', 'layers.3.ffn.experts.22.w2.weight', 'layers.3.ffn.experts.22.w3.scale', 'layers.3.ffn.experts.22.w3.weight', 'layers.3.ffn.experts.23.w1.scale', 'layers.3.ffn.experts.23.w1.weight', 'layers.3.ffn.experts.23.w2.scale', 'layers.3.ffn.experts.23.w2.weight', 'layers.3.ffn.experts.23.w3.scale', 'layers.3.ffn.experts.23.w3.weight', 'layers.3.ffn.experts.24.w1.scale', 'layers.3.ffn.experts.24.w1.weight', 'layers.3.ffn.experts.24.w2.scale', 'layers.3.ffn.experts.24.w2.weight', 'layers.3.ffn.experts.24.w3.scale', 'layers.3.ffn.experts.24.w3.weight', 'layers.3.ffn.experts.25.w1.scale', 'layers.3.ffn.experts.25.w1.weight', 'layers.3.ffn.experts.25.w2.scale', 'layers.3.ffn.experts.25.w2.weight', 'layers.3.ffn.experts.25.w3.scale', 'layers.3.ffn.experts.25.w3.weight', 'layers.3.ffn.experts.26.w1.scale', 'layers.3.ffn.experts.26.w1.weight', 'layers.3.ffn.experts.26.w2.scale', 'layers.3.ffn.experts.26.w2.weight', 'layers.3.ffn.experts.26.w3.scale', 'layers.3.ffn.experts.26.w3.weight', 'layers.3.ffn.experts.27.w1.scale', 'layers.3.ffn.experts.27.w1.weight', 'layers.3.ffn.experts.27.w2.scale', 'layers.3.ffn.experts.27.w2.weight', 'layers.3.ffn.experts.27.w3.scale', 'layers.3.ffn.experts.27.w3.weight', 'layers.3.ffn.experts.28.w1.scale', 'layers.3.ffn.experts.28.w1.weight', 'layers.3.ffn.experts.28.w2.scale', 'layers.3.ffn.experts.28.w2.weight', 'layers.3.ffn.experts.28.w3.scale', 'layers.3.ffn.experts.28.w3.weight', 'layers.3.ffn.experts.29.w1.scale', 'layers.3.ffn.experts.29.w1.weight', 'layers.3.ffn.experts.29.w2.scale', 'layers.3.ffn.experts.29.w2.weight', 'layers.3.ffn.experts.29.w3.scale', 'layers.3.ffn.experts.29.w3.weight', 'layers.3.ffn.experts.3.w1.scale', 'layers.3.ffn.experts.3.w1.weight', 'layers.3.ffn.experts.3.w2.scale', 'layers.3.ffn.experts.3.w2.weight', 'layers.3.ffn.experts.3.w3.scale', 'layers.3.ffn.experts.3.w3.weight', 'layers.3.ffn.experts.30.w1.scale', 'layers.3.ffn.experts.30.w1.weight', 'layers.3.ffn.experts.30.w2.scale', 'layers.3.ffn.experts.30.w2.weight', 'layers.3.ffn.experts.30.w3.scale', 'layers.3.ffn.experts.30.w3.weight', 'layers.3.ffn.experts.31.w1.scale', 'layers.3.ffn.experts.31.w1.weight', 'layers.3.ffn.experts.31.w3.weight', 'layers.3.ffn.experts.4.w1.scale', 'layers.3.ffn.experts.4.w1.weight', 'layers.3.ffn.experts.4.w2.scale', 'layers.3.ffn.experts.4.w2.weight', 'layers.3.ffn.experts.4.w3.scale', 'layers.3.ffn.experts.4.w3.weight', 'layers.3.ffn.experts.5.w1.scale', 'layers.3.ffn.experts.5.w1.weight', 'layers.3.ffn.experts.5.w2.scale', 'layers.3.ffn.experts.5.w2.weight', 'layers.3.ffn.experts.5.w3.scale', 'layers.3.ffn.experts.5.w3.weight', 'layers.3.ffn.experts.6.w1.scale', 'layers.3.ffn.experts.6.w1.weight', 'layers.3.ffn.experts.6.w2.scale', 'layers.3.ffn.experts.6.w2.weight', 'layers.3.ffn.experts.6.w3.scale', 'layers.3.ffn.experts.6.w3.weight', 'layers.3.ffn.experts.7.w1.scale', 'layers.3.ffn.experts.7.w1.weight', 'layers.3.ffn.experts.7.w2.scale', 'layers.3.ffn.experts.7.w2.weight', 'layers.3.ffn.experts.7.w3.scale', 'layers.3.ffn.experts.7.w3.weight', 'layers.3.ffn.experts.8.w1.scale', 'layers.3.ffn.experts.8.w1.weight', 'layers.3.ffn.experts.8.w2.scale', 'layers.3.ffn.experts.8.w2.weight', 'layers.3.ffn.experts.8.w3.scale', 'layers.3.ffn.experts.8.w3.weight', 'layers.3.ffn.experts.9.w1.scale', 'layers.3.ffn.experts.9.w1.weight', 'layers.3.ffn.experts.9.w2.scale', 'layers.3.ffn.experts.9.w2.weight', 'layers.3.ffn.experts.9.w3.scale', 'layers.3.ffn.experts.9.w3.weight', 'layers.3.ffn.gate.bias', 'layers.3.ffn.gate.weight', 'layers.3.ffn.shared_experts.w1.scale', 'layers.3.ffn.shared_experts.w1.weight', 'layers.3.ffn.shared_experts.w2.scale', 'layers.3.ffn.shared_experts.w2.weight', 'layers.3.ffn.shared_experts.w3.scale', 'layers.3.ffn.shared_experts.w3.weight', 'layers.5.attn_norm.weight', 'layers.5.ffn.experts.194.w1.scale', 'layers.5.ffn.experts.194.w2.scale', 'layers.5.ffn.experts.194.w2.weight', 'layers.5.ffn.experts.194.w3.scale', 'layers.5.ffn.experts.194.w3.weight', 'layers.5.ffn.experts.195.w1.scale', 'layers.5.ffn.experts.195.w1.weight', 'layers.5.ffn.experts.195.w2.scale', 'layers.5.ffn.experts.195.w2.weight', 'layers.5.ffn.experts.195.w3.scale', 'layers.5.ffn.experts.195.w3.weight', 'layers.5.ffn.experts.196.w1.scale', 'layers.5.ffn.experts.196.w1.weight', 'layers.5.ffn.experts.196.w2.scale', 'layers.5.ffn.experts.196.w2.weight', 'layers.5.ffn.experts.196.w3.scale', 'layers.5.ffn.experts.196.w3.weight', 'layers.5.ffn.experts.197.w1.scale', 'layers.5.ffn.experts.197.w1.weight', 'layers.5.ffn.experts.197.w2.scale', 'layers.5.ffn.experts.197.w2.weight', 'layers.5.ffn.experts.197.w3.scale', 'layers.5.ffn.experts.197.w3.weight', 'layers.5.ffn.experts.198.w1.scale', 'layers.5.ffn.experts.198.w1.weight', 'layers.5.ffn.experts.198.w2.scale', 'layers.5.ffn.experts.198.w2.weight', 'layers.5.ffn.experts.198.w3.scale', 'layers.5.ffn.experts.198.w3.weight', 'layers.5.ffn.experts.199.w1.scale', 'layers.5.ffn.experts.199.w1.weight', 'layers.5.ffn.experts.199.w2.scale', 'layers.5.ffn.experts.199.w2.weight', 'layers.5.ffn.experts.199.w3.scale', 'layers.5.ffn.experts.199.w3.weight', 'layers.5.ffn.experts.200.w1.scale', 'layers.5.ffn.experts.200.w1.weight', 'layers.5.ffn.experts.200.w2.scale', 'layers.5.ffn.experts.200.w2.weight', 'layers.5.ffn.experts.200.w3.scale', 'layers.5.ffn.experts.200.w3.weight', 'layers.5.ffn.experts.201.w1.scale', 'layers.5.ffn.experts.201.w1.weight', 'layers.5.ffn.experts.201.w2.scale', 'layers.5.ffn.experts.201.w2.weight', 'layers.5.ffn.experts.201.w3.scale', 'layers.5.ffn.experts.201.w3.weight', 'layers.5.ffn.experts.202.w1.scale', 'layers.5.ffn.experts.202.w1.weight', 'layers.5.ffn.experts.202.w2.scale', 'layers.5.ffn.experts.202.w2.weight', 'layers.5.ffn.experts.202.w3.scale', 'layers.5.ffn.experts.202.w3.weight', 'layers.5.ffn.experts.203.w1.scale', 'layers.5.ffn.experts.203.w1.weight', 'layers.5.ffn.experts.203.w2.scale', 'layers.5.ffn.experts.203.w2.weight', 'layers.5.ffn.experts.203.w3.scale', 'layers.5.ffn.experts.203.w3.weight', 'layers.5.ffn.experts.204.w1.scale', 'layers.5.ffn.experts.204.w1.weight', 'layers.5.ffn.experts.204.w2.scale', 'layers.5.ffn.experts.204.w2.weight', 'layers.5.ffn.experts.204.w3.scale', 'layers.5.ffn.experts.204.w3.weight', 'layers.5.ffn.experts.205.w1.scale', 'layers.5.ffn.experts.205.w1.weight', 'layers.5.ffn.experts.205.w2.scale', 'layers.5.ffn.experts.205.w2.weight', 'layers.5.ffn.experts.205.w3.scale', 'layers.5.ffn.experts.205.w3.weight', 'layers.5.ffn.experts.206.w1.scale', 'layers.5.ffn.experts.206.w1.weight', 'layers.5.ffn.experts.206.w2.scale', 'layers.5.ffn.experts.206.w2.weight', 'layers.5.ffn.experts.206.w3.scale', 'layers.5.ffn.experts.206.w3.weight', 'layers.5.ffn.experts.207.w1.scale', 'layers.5.ffn.experts.207.w1.weight', 'layers.5.ffn.experts.207.w2.scale', 'layers.5.ffn.experts.207.w2.weight', 'layers.5.ffn.experts.207.w3.scale', 'layers.5.ffn.experts.207.w3.weight', 'layers.5.ffn.experts.208.w1.scale', 'layers.5.ffn.experts.208.w1.weight', 'layers.5.ffn.experts.208.w2.scale', 'layers.5.ffn.experts.208.w2.weight', 'layers.5.ffn.experts.208.w3.scale', 'layers.5.ffn.experts.208.w3.weight', 'layers.5.ffn.experts.209.w1.scale', 'layers.5.ffn.experts.209.w1.weight', 'layers.5.ffn.experts.209.w2.scale', 'layers.5.ffn.experts.209.w2.weight', 'layers.5.ffn.experts.209.w3.scale', 'layers.5.ffn.experts.209.w3.weight', 'layers.5.ffn.experts.210.w1.scale', 'layers.5.ffn.experts.210.w1.weight', 'layers.5.ffn.experts.210.w2.scale', 'layers.5.ffn.experts.210.w2.weight', 'layers.5.ffn.experts.210.w3.scale', 'layers.5.ffn.experts.210.w3.weight', 'layers.5.ffn.experts.211.w1.scale', 'layers.5.ffn.experts.211.w1.weight', 'layers.5.ffn.experts.211.w2.scale', 'layers.5.ffn.experts.211.w2.weight', 'layers.5.ffn.experts.211.w3.scale', 'layers.5.ffn.experts.211.w3.weight', 'layers.5.ffn.experts.212.w1.scale', 'layers.5.ffn.experts.212.w1.weight', 'layers.5.ffn.experts.212.w2.scale', 'layers.5.ffn.experts.212.w2.weight', 'layers.5.ffn.experts.212.w3.scale', 'layers.5.ffn.experts.212.w3.weight', 'layers.5.ffn.experts.213.w1.scale', 'layers.5.ffn.experts.213.w1.weight', 'layers.5.ffn.experts.213.w2.scale', 'layers.5.ffn.experts.213.w2.weight', 'layers.5.ffn.experts.213.w3.scale', 'layers.5.ffn.experts.213.w3.weight', 'layers.5.ffn.experts.214.w1.scale', 'layers.5.ffn.experts.214.w1.weight', 'layers.5.ffn.experts.214.w2.scale', 'layers.5.ffn.experts.214.w2.weight', 'layers.5.ffn.experts.214.w3.scale', 'layers.5.ffn.experts.214.w3.weight', 'layers.5.ffn.experts.215.w1.scale', 'layers.5.ffn.experts.215.w1.weight', 'layers.5.ffn.experts.215.w2.scale', 'layers.5.ffn.experts.215.w2.weight', 'layers.5.ffn.experts.215.w3.scale', 'layers.5.ffn.experts.215.w3.weight', 'layers.5.ffn.experts.216.w1.scale', 'layers.5.ffn.experts.216.w1.weight', 'layers.5.ffn.experts.216.w2.scale', 'layers.5.ffn.experts.216.w2.weight', 'layers.5.ffn.experts.216.w3.scale', 'layers.5.ffn.experts.216.w3.weight', 'layers.5.ffn.experts.217.w1.scale', 'layers.5.ffn.experts.217.w1.weight', 'layers.5.ffn.experts.217.w2.scale', 'layers.5.ffn.experts.217.w2.weight', 'layers.5.ffn.experts.217.w3.scale', 'layers.5.ffn.experts.217.w3.weight', 'layers.5.ffn.experts.218.w1.scale', 'layers.5.ffn.experts.218.w1.weight', 'layers.5.ffn.experts.218.w2.scale', 'layers.5.ffn.experts.218.w2.weight', 'layers.5.ffn.experts.218.w3.scale', 'layers.5.ffn.experts.218.w3.weight', 'layers.5.ffn.experts.219.w1.scale', 'layers.5.ffn.experts.219.w1.weight', 'layers.5.ffn.experts.219.w2.scale', 'layers.5.ffn.experts.219.w2.weight', 'layers.5.ffn.experts.219.w3.scale', 'layers.5.ffn.experts.219.w3.weight', 'layers.5.ffn.experts.220.w1.scale', 'layers.5.ffn.experts.220.w1.weight', 'layers.5.ffn.experts.220.w2.scale', 'layers.5.ffn.experts.220.w2.weight', 'layers.5.ffn.experts.220.w3.scale', 'layers.5.ffn.experts.220.w3.weight', 'layers.5.ffn.experts.221.w1.scale', 'layers.5.ffn.experts.221.w1.weight', 'layers.5.ffn.experts.221.w2.scale', 'layers.5.ffn.experts.221.w2.weight', 'layers.5.ffn.experts.221.w3.scale', 'layers.5.ffn.experts.221.w3.weight', 'layers.5.ffn.experts.222.w1.scale', 'layers.5.ffn.experts.222.w1.weight', 'layers.5.ffn.experts.222.w2.scale', 'layers.5.ffn.experts.222.w2.weight', 'layers.5.ffn.experts.222.w3.scale', 'layers.5.ffn.experts.222.w3.weight', 'layers.5.ffn.experts.223.w1.scale', 'layers.5.ffn.experts.223.w1.weight', 'layers.5.ffn.experts.223.w2.scale', 'layers.5.ffn.experts.223.w2.weight', 'layers.5.ffn.experts.223.w3.scale', 'layers.5.ffn.experts.223.w3.weight', 'layers.5.ffn.experts.224.w1.scale', 'layers.5.ffn.experts.224.w1.weight', 'layers.5.ffn.experts.224.w2.scale', 'layers.5.ffn.experts.224.w2.weight', 'layers.5.ffn.experts.224.w3.scale', 'layers.5.ffn.experts.224.w3.weight', 'layers.5.ffn.experts.225.w1.scale', 'layers.5.ffn.experts.225.w1.weight', 'layers.5.ffn.experts.225.w2.scale', 'layers.5.ffn.experts.225.w2.weight', 'layers.5.ffn.experts.225.w3.scale', 'layers.5.ffn.experts.225.w3.weight', 'layers.5.ffn.experts.226.w1.scale', 'layers.5.ffn.experts.226.w1.weight', 'layers.5.ffn.experts.226.w2.scale', 'layers.5.ffn.experts.226.w2.weight', 'layers.5.ffn.experts.226.w3.scale', 'layers.5.ffn.experts.226.w3.weight', 'layers.5.ffn.experts.227.w1.scale', 'layers.5.ffn.experts.227.w1.weight', 'layers.5.ffn.experts.227.w2.scale', 'layers.5.ffn.experts.227.w2.weight', 'layers.5.ffn.experts.227.w3.scale', 'layers.5.ffn.experts.227.w3.weight', 'layers.5.ffn.experts.228.w1.scale', 'layers.5.ffn.experts.228.w1.weight', 'layers.5.ffn.experts.228.w2.scale', 'layers.5.ffn.experts.228.w2.weight', 'layers.5.ffn.experts.228.w3.scale', 'layers.5.ffn.experts.228.w3.weight', 'layers.5.ffn.experts.229.w1.scale', 'layers.5.ffn.experts.229.w1.weight', 'layers.5.ffn.experts.229.w2.scale', 'layers.5.ffn.experts.229.w2.weight', 'layers.5.ffn.experts.229.w3.scale', 'layers.5.ffn.experts.229.w3.weight', 'layers.5.ffn.experts.230.w1.scale', 'layers.5.ffn.experts.230.w1.weight', 'layers.5.ffn.experts.230.w2.scale', 'layers.5.ffn.experts.230.w2.weight', 'layers.5.ffn.experts.230.w3.scale', 'layers.5.ffn.experts.230.w3.weight', 'layers.5.ffn.experts.231.w1.scale', 'layers.5.ffn.experts.231.w1.weight', 'layers.5.ffn.experts.231.w2.scale', 'layers.5.ffn.experts.231.w2.weight', 'layers.5.ffn.experts.231.w3.scale', 'layers.5.ffn.experts.231.w3.weight', 'layers.5.ffn.experts.232.w1.scale', 'layers.5.ffn.experts.232.w1.weight', 'layers.5.ffn.experts.232.w2.scale', 'layers.5.ffn.experts.232.w2.weight', 'layers.5.ffn.experts.232.w3.scale', 'layers.5.ffn.experts.232.w3.weight', 'layers.5.ffn.experts.233.w1.scale', 'layers.5.ffn.experts.233.w1.weight', 'layers.5.ffn.experts.233.w2.scale', 'layers.5.ffn.experts.233.w2.weight', 'layers.5.ffn.experts.233.w3.scale', 'layers.5.ffn.experts.233.w3.weight', 'layers.5.ffn.experts.234.w1.scale', 'layers.5.ffn.experts.234.w1.weight', 'layers.5.ffn.experts.234.w2.scale', 'layers.5.ffn.experts.234.w2.weight', 'layers.5.ffn.experts.234.w3.scale', 'layers.5.ffn.experts.234.w3.weight', 'layers.5.ffn.experts.235.w1.scale', 'layers.5.ffn.experts.235.w1.weight', 'layers.5.ffn.experts.235.w2.scale', 'layers.5.ffn.experts.235.w2.weight', 'layers.5.ffn.experts.235.w3.scale', 'layers.5.ffn.experts.235.w3.weight', 'layers.5.ffn.experts.236.w1.scale', 'layers.5.ffn.experts.236.w1.weight', 'layers.5.ffn.experts.236.w2.scale', 'layers.5.ffn.experts.236.w2.weight', 'layers.5.ffn.experts.236.w3.scale', 'layers.5.ffn.experts.236.w3.weight', 'layers.5.ffn.experts.237.w1.scale', 'layers.5.ffn.experts.237.w1.weight', 'layers.5.ffn.experts.237.w2.scale', 'layers.5.ffn.experts.237.w2.weight', 'layers.5.ffn.experts.237.w3.scale', 'layers.5.ffn.experts.237.w3.weight', 'layers.5.ffn.experts.238.w1.scale', 'layers.5.ffn.experts.238.w1.weight', 'layers.5.ffn.experts.238.w2.scale', 'layers.5.ffn.experts.238.w2.weight', 'layers.5.ffn.experts.238.w3.scale', 'layers.5.ffn.experts.238.w3.weight', 'layers.5.ffn.experts.239.w1.scale', 'layers.5.ffn.experts.239.w1.weight', 'layers.5.ffn.experts.239.w2.scale', 'layers.5.ffn.experts.239.w2.weight', 'layers.5.ffn.experts.239.w3.scale', 'layers.5.ffn.experts.239.w3.weight', 'layers.5.ffn.experts.240.w1.scale', 'layers.5.ffn.experts.240.w1.weight', 'layers.5.ffn.experts.240.w2.scale', 'layers.5.ffn.experts.240.w2.weight', 'layers.5.ffn.experts.240.w3.scale', 'layers.5.ffn.experts.240.w3.weight', 'layers.5.ffn.experts.241.w1.scale', 'layers.5.ffn.experts.241.w1.weight', 'layers.5.ffn.experts.241.w2.scale', 'layers.5.ffn.experts.241.w2.weight', 'layers.5.ffn.experts.241.w3.scale', 'layers.5.ffn.experts.241.w3.weight', 'layers.5.ffn.experts.242.w1.scale', 'layers.5.ffn.experts.242.w1.weight', 'layers.5.ffn.experts.242.w2.scale', 'layers.5.ffn.experts.242.w2.weight', 'layers.5.ffn.experts.242.w3.scale', 'layers.5.ffn.experts.242.w3.weight', 'layers.5.ffn.experts.243.w1.scale', 'layers.5.ffn.experts.243.w1.weight', 'layers.5.ffn.experts.243.w2.scale', 'layers.5.ffn.experts.243.w2.weight', 'layers.5.ffn.experts.243.w3.scale', 'layers.5.ffn.experts.243.w3.weight', 'layers.5.ffn.experts.244.w1.scale', 'layers.5.ffn.experts.244.w1.weight', 'layers.5.ffn.experts.244.w2.scale', 'layers.5.ffn.experts.244.w2.weight', 'layers.5.ffn.experts.244.w3.scale', 'layers.5.ffn.experts.244.w3.weight', 'layers.5.ffn.experts.245.w1.scale', 'layers.5.ffn.experts.245.w1.weight', 'layers.5.ffn.experts.245.w2.scale', 'layers.5.ffn.experts.245.w2.weight', 'layers.5.ffn.experts.245.w3.scale', 'layers.5.ffn.experts.245.w3.weight', 'layers.5.ffn.experts.246.w1.scale', 'layers.5.ffn.experts.246.w1.weight', 'layers.5.ffn.experts.246.w2.scale', 'layers.5.ffn.experts.246.w2.weight', 'layers.5.ffn.experts.246.w3.scale', 'layers.5.ffn.experts.246.w3.weight', 'layers.5.ffn.experts.247.w1.scale', 'layers.5.ffn.experts.247.w1.weight', 'layers.5.ffn.experts.247.w2.scale', 'layers.5.ffn.experts.247.w2.weight', 'layers.5.ffn.experts.247.w3.scale', 'layers.5.ffn.experts.247.w3.weight', 'layers.5.ffn.experts.248.w1.scale', 'layers.5.ffn.experts.248.w1.weight', 'layers.5.ffn.experts.248.w2.scale', 'layers.5.ffn.experts.248.w2.weight', 'layers.5.ffn.experts.248.w3.scale', 'layers.5.ffn.experts.248.w3.weight', 'layers.5.ffn.experts.249.w1.scale', 'layers.5.ffn.experts.249.w1.weight', 'layers.5.ffn.experts.249.w2.scale', 'layers.5.ffn.experts.249.w2.weight', 'layers.5.ffn.experts.249.w3.scale', 'layers.5.ffn.experts.249.w3.weight', 'layers.5.ffn.experts.250.w1.scale', 'layers.5.ffn.experts.250.w1.weight', 'layers.5.ffn.experts.250.w2.scale', 'layers.5.ffn.experts.250.w2.weight', 'layers.5.ffn.experts.250.w3.scale', 'layers.5.ffn.experts.250.w3.weight', 'layers.5.ffn.experts.251.w1.scale', 'layers.5.ffn.experts.251.w1.weight', 'layers.5.ffn.experts.251.w2.scale', 'layers.5.ffn.experts.251.w2.weight', 'layers.5.ffn.experts.251.w3.scale', 'layers.5.ffn.experts.251.w3.weight', 'layers.5.ffn.experts.252.w1.scale', 'layers.5.ffn.experts.252.w1.weight', 'layers.5.ffn.experts.252.w2.scale', 'layers.5.ffn.experts.252.w2.weight', 'layers.5.ffn.experts.252.w3.scale', 'layers.5.ffn.experts.252.w3.weight', 'layers.5.ffn.experts.253.w1.scale', 'layers.5.ffn.experts.253.w1.weight', 'layers.5.ffn.experts.253.w2.scale', 'layers.5.ffn.experts.253.w2.weight', 'layers.5.ffn.experts.253.w3.scale', 'layers.5.ffn.experts.253.w3.weight', 'layers.5.ffn.experts.254.w1.scale', 'layers.5.ffn.experts.254.w1.weight', 'layers.5.ffn.experts.254.w2.scale', 'layers.5.ffn.experts.254.w2.weight', 'layers.5.ffn.experts.254.w3.scale', 'layers.5.ffn.experts.254.w3.weight', 'layers.5.ffn.experts.255.w1.scale', 'layers.5.ffn.experts.255.w1.weight', 'layers.5.ffn.experts.255.w2.scale', 'layers.5.ffn.experts.255.w2.weight', 'layers.5.ffn.experts.255.w3.scale', 'layers.5.ffn.experts.255.w3.weight', 'layers.5.ffn_norm.weight', 'layers.6.attn.kv_norm.weight', 'layers.6.attn.q_norm.weight', 'layers.6.attn.wkv_a.scale', 'layers.6.attn.wkv_a.weight', 'layers.6.attn.wkv_b.scale', 'layers.6.attn.wkv_b.weight', 'layers.6.attn.wo.scale', 'layers.6.attn.wo.weight', 'layers.6.attn.wq_a.scale', 'layers.6.attn.wq_a.weight', 'layers.6.attn.wq_b.scale', 'layers.6.attn.wq_b.weight', 'layers.6.ffn.experts.0.w1.scale', 'layers.6.ffn.experts.0.w1.weight', 'layers.6.ffn.experts.0.w2.scale', 'layers.6.ffn.experts.0.w2.weight', 'layers.6.ffn.experts.0.w3.scale', 'layers.6.ffn.experts.0.w3.weight', 'layers.6.ffn.experts.1.w1.scale', 'layers.6.ffn.experts.1.w1.weight', 'layers.6.ffn.experts.1.w2.scale', 'layers.6.ffn.experts.1.w2.weight', 'layers.6.ffn.experts.1.w3.scale', 'layers.6.ffn.experts.1.w3.weight', 'layers.6.ffn.experts.10.w1.scale', 'layers.6.ffn.experts.10.w1.weight', 'layers.6.ffn.experts.10.w2.scale', 'layers.6.ffn.experts.10.w2.weight', 'layers.6.ffn.experts.10.w3.scale', 'layers.6.ffn.experts.10.w3.weight', 'layers.6.ffn.experts.11.w1.scale', 'layers.6.ffn.experts.11.w1.weight', 'layers.6.ffn.experts.11.w2.scale', 'layers.6.ffn.experts.11.w2.weight', 'layers.6.ffn.experts.11.w3.scale', 'layers.6.ffn.experts.11.w3.weight', 'layers.6.ffn.experts.12.w1.scale', 'layers.6.ffn.experts.12.w1.weight', 'layers.6.ffn.experts.12.w2.scale', 'layers.6.ffn.experts.12.w2.weight', 'layers.6.ffn.experts.12.w3.scale', 'layers.6.ffn.experts.12.w3.weight', 'layers.6.ffn.experts.13.w1.scale', 'layers.6.ffn.experts.13.w1.weight', 'layers.6.ffn.experts.13.w2.scale', 'layers.6.ffn.experts.13.w2.weight', 'layers.6.ffn.experts.13.w3.scale', 'layers.6.ffn.experts.13.w3.weight', 'layers.6.ffn.experts.14.w1.scale', 'layers.6.ffn.experts.14.w1.weight', 'layers.6.ffn.experts.14.w2.scale', 'layers.6.ffn.experts.14.w2.weight', 'layers.6.ffn.experts.14.w3.scale', 'layers.6.ffn.experts.14.w3.weight', 'layers.6.ffn.experts.15.w1.scale', 'layers.6.ffn.experts.15.w1.weight', 'layers.6.ffn.experts.15.w2.scale', 'layers.6.ffn.experts.15.w2.weight', 'layers.6.ffn.experts.15.w3.scale', 'layers.6.ffn.experts.15.w3.weight', 'layers.6.ffn.experts.16.w1.scale', 'layers.6.ffn.experts.16.w1.weight', 'layers.6.ffn.experts.16.w2.scale', 'layers.6.ffn.experts.16.w2.weight', 'layers.6.ffn.experts.16.w3.scale', 'layers.6.ffn.experts.16.w3.weight', 'layers.6.ffn.experts.17.w1.scale', 'layers.6.ffn.experts.17.w1.weight', 'layers.6.ffn.experts.17.w2.scale', 'layers.6.ffn.experts.17.w2.weight', 'layers.6.ffn.experts.17.w3.scale', 'layers.6.ffn.experts.17.w3.weight', 'layers.6.ffn.experts.18.w1.scale', 'layers.6.ffn.experts.18.w1.weight', 'layers.6.ffn.experts.18.w2.scale', 'layers.6.ffn.experts.18.w2.weight', 'layers.6.ffn.experts.18.w3.scale', 'layers.6.ffn.experts.18.w3.weight', 'layers.6.ffn.experts.19.w1.scale', 'layers.6.ffn.experts.19.w1.weight', 'layers.6.ffn.experts.19.w2.scale', 'layers.6.ffn.experts.19.w2.weight', 'layers.6.ffn.experts.19.w3.scale', 'layers.6.ffn.experts.19.w3.weight', 'layers.6.ffn.experts.2.w1.scale', 'layers.6.ffn.experts.2.w1.weight', 'layers.6.ffn.experts.2.w2.scale', 'layers.6.ffn.experts.2.w2.weight', 'layers.6.ffn.experts.2.w3.scale', 'layers.6.ffn.experts.2.w3.weight', 'layers.6.ffn.experts.20.w1.scale', 'layers.6.ffn.experts.20.w1.weight', 'layers.6.ffn.experts.20.w2.scale', 'layers.6.ffn.experts.20.w2.weight', 'layers.6.ffn.experts.20.w3.scale', 'layers.6.ffn.experts.20.w3.weight', 'layers.6.ffn.experts.21.w1.scale', 'layers.6.ffn.experts.21.w1.weight', 'layers.6.ffn.experts.21.w2.scale', 'layers.6.ffn.experts.21.w2.weight', 'layers.6.ffn.experts.21.w3.scale', 'layers.6.ffn.experts.21.w3.weight', 'layers.6.ffn.experts.22.w1.scale', 'layers.6.ffn.experts.22.w1.weight', 'layers.6.ffn.experts.22.w2.scale', 'layers.6.ffn.experts.22.w2.weight', 'layers.6.ffn.experts.22.w3.scale', 'layers.6.ffn.experts.22.w3.weight', 'layers.6.ffn.experts.23.w1.scale', 'layers.6.ffn.experts.23.w1.weight', 'layers.6.ffn.experts.23.w2.scale', 'layers.6.ffn.experts.23.w2.weight', 'layers.6.ffn.experts.23.w3.scale', 'layers.6.ffn.experts.23.w3.weight', 'layers.6.ffn.experts.24.w1.scale', 'layers.6.ffn.experts.24.w1.weight', 'layers.6.ffn.experts.24.w2.scale', 'layers.6.ffn.experts.24.w2.weight', 'layers.6.ffn.experts.24.w3.scale', 'layers.6.ffn.experts.24.w3.weight', 'layers.6.ffn.experts.25.w1.scale', 'layers.6.ffn.experts.25.w1.weight', 'layers.6.ffn.experts.25.w2.scale', 'layers.6.ffn.experts.25.w2.weight', 'layers.6.ffn.experts.25.w3.scale', 'layers.6.ffn.experts.25.w3.weight', 'layers.6.ffn.experts.26.w1.scale', 'layers.6.ffn.experts.26.w1.weight', 'layers.6.ffn.experts.26.w2.scale', 'layers.6.ffn.experts.26.w2.weight', 'layers.6.ffn.experts.26.w3.scale', 'layers.6.ffn.experts.26.w3.weight', 'layers.6.ffn.experts.27.w1.scale', 'layers.6.ffn.experts.27.w1.weight', 'layers.6.ffn.experts.27.w2.scale', 'layers.6.ffn.experts.27.w2.weight', 'layers.6.ffn.experts.27.w3.scale', 'layers.6.ffn.experts.27.w3.weight', 'layers.6.ffn.experts.28.w1.scale', 'layers.6.ffn.experts.28.w1.weight', 'layers.6.ffn.experts.28.w2.scale', 'layers.6.ffn.experts.28.w2.weight', 'layers.6.ffn.experts.28.w3.scale', 'layers.6.ffn.experts.28.w3.weight', 'layers.6.ffn.experts.29.w1.scale', 'layers.6.ffn.experts.29.w1.weight', 'layers.6.ffn.experts.29.w2.scale', 'layers.6.ffn.experts.29.w2.weight', 'layers.6.ffn.experts.29.w3.scale', 'layers.6.ffn.experts.29.w3.weight', 'layers.6.ffn.experts.3.w1.scale', 'layers.6.ffn.experts.3.w1.weight', 'layers.6.ffn.experts.3.w2.scale', 'layers.6.ffn.experts.3.w2.weight', 'layers.6.ffn.experts.3.w3.scale', 'layers.6.ffn.experts.3.w3.weight', 'layers.6.ffn.experts.30.w1.scale', 'layers.6.ffn.experts.30.w1.weight', 'layers.6.ffn.experts.30.w3.weight', 'layers.6.ffn.experts.4.w1.scale', 'layers.6.ffn.experts.4.w1.weight', 'layers.6.ffn.experts.4.w2.scale', 'layers.6.ffn.experts.4.w2.weight', 'layers.6.ffn.experts.4.w3.scale', 'layers.6.ffn.experts.4.w3.weight', 'layers.6.ffn.experts.5.w1.scale', 'layers.6.ffn.experts.5.w1.weight', 'layers.6.ffn.experts.5.w2.scale', 'layers.6.ffn.experts.5.w2.weight', 'layers.6.ffn.experts.5.w3.scale', 'layers.6.ffn.experts.5.w3.weight', 'layers.6.ffn.experts.6.w1.scale', 'layers.6.ffn.experts.6.w1.weight', 'layers.6.ffn.experts.6.w2.scale', 'layers.6.ffn.experts.6.w2.weight', 'layers.6.ffn.experts.6.w3.scale', 'layers.6.ffn.experts.6.w3.weight', 'layers.6.ffn.experts.7.w1.scale', 'layers.6.ffn.experts.7.w1.weight', 'layers.6.ffn.experts.7.w2.scale', 'layers.6.ffn.experts.7.w2.weight', 'layers.6.ffn.experts.7.w3.scale', 'layers.6.ffn.experts.7.w3.weight', 'layers.6.ffn.experts.8.w1.scale', 'layers.6.ffn.experts.8.w1.weight', 'layers.6.ffn.experts.8.w2.scale', 'layers.6.ffn.experts.8.w2.weight', 'layers.6.ffn.experts.8.w3.scale', 'layers.6.ffn.experts.8.w3.weight', 'layers.6.ffn.experts.9.w1.scale', 'layers.6.ffn.experts.9.w1.weight', 'layers.6.ffn.experts.9.w2.scale', 'layers.6.ffn.experts.9.w2.weight', 'layers.6.ffn.experts.9.w3.scale', 'layers.6.ffn.experts.9.w3.weight', 'layers.6.ffn.gate.bias', 'layers.6.ffn.gate.weight', 'layers.6.ffn.shared_experts.w1.scale', 'layers.6.ffn.shared_experts.w1.weight', 'layers.6.ffn.shared_experts.w2.scale', 'layers.6.ffn.shared_experts.w2.weight', 'layers.6.ffn.shared_experts.w3.scale', 'layers.6.ffn.shared_experts.w3.weight'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66093938-e0e3-4004-a0fc-117b4072eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict=model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f9c4e1c-6748-4a69-8103-93317e067839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "962ebe5c-71b3-4bb7-bcc1-740eece1a13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "846"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8798564-b46d-4492-84e1-f38cc0ebba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing, unexpected = model.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0faf1aba-6841-4a40-90ea-35ada8f24e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unexpected) #Ok some are getting loaded -> maybe the ones I need are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b65f1216-2fc0-485a-98db-b4cab3eb591b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.5078e+08, dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.wq_a.weight.detach().abs().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9127052-e505-4b09-877a-bf57d5a3c1e9",
   "metadata": {},
   "source": [
    "Numbers!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f0fee78-2f10-468a-8076-d14fa0709484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ -22.0000,  -72.0000,   88.0000,  ...,   -9.0000, -208.0000,\n",
       "          -28.0000],\n",
       "        [ 128.0000,   14.0000,   16.0000,  ...,  104.0000,  -64.0000,\n",
       "           26.0000],\n",
       "        [  72.0000,  -36.0000,   64.0000,  ..., -120.0000,   80.0000,\n",
       "          -72.0000],\n",
       "        ...,\n",
       "        [-144.0000,   80.0000,   48.0000,  ...,  -72.0000,  -96.0000,\n",
       "           72.0000],\n",
       "        [ -80.0000,  120.0000,   72.0000,  ...,  -44.0000,  112.0000,\n",
       "          112.0000],\n",
       "        [ 224.0000,    4.5000,  -56.0000,  ...,  160.0000,  -64.0000,\n",
       "           36.0000]], dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.wq_a.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d73a8c5e-aab0-4edc-8f60-13aa92db25a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[0].attn.wq_a.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a04d3054-2415-40ba-a830-e9b3f9da5fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.3804e-02,  2.5879e-02,  1.7334e-02,  ..., -3.6377e-02,\n",
       "         -1.7334e-02, -1.0437e-02],\n",
       "        [-2.1240e-02,  2.8076e-02,  1.0400e-01,  ..., -1.3504e-03,\n",
       "         -2.0874e-02, -1.1230e-02],\n",
       "        [-1.4465e-02,  1.0315e-02,  1.4771e-02,  ...,  2.8076e-03,\n",
       "          3.1738e-02, -1.9897e-02],\n",
       "        ...,\n",
       "        [ 1.4725e-03, -8.0566e-03,  1.5488e-03,  ..., -1.9379e-03,\n",
       "         -4.6539e-04,  3.3112e-03],\n",
       "        [ 4.7607e-03,  3.2196e-03, -5.9891e-04,  ..., -7.2098e-04,\n",
       "         -2.3193e-03, -1.0986e-02],\n",
       "        [ 5.3346e-06, -7.1716e-03,  6.7139e-04,  ..., -3.8605e-03,\n",
       "         -6.1340e-03, -2.5635e-03]], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de144540-2194-4a01-946a-e235d9557f1f",
   "metadata": {},
   "source": [
    "- OK NICE!\n",
    "- Took some hacking, but I should be able to trace like actually values through this thing now\n",
    "- Next I'll convert a few more tensors (into a new directory), make a clean from scratch notebook, and get to tracing and visualizing! Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad26431-7fd8-4b9d-a464-139cec2960a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69243041-880e-4bec-8aee-bf0a05f885cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee0dd4-373a-4552-a5f1-9f9d1ade0149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b7efb-1603-463b-b902-231320cdd63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d065c2-fe3a-46f6-9be4-f971fa95a837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54e96ee3-9a37-4d01-a599-faee1c157b52",
   "metadata": {},
   "source": [
    "`load_model` not quite working as expected, getting a little deeper. \n",
    "```\n",
    "    state_dict = load_file(filename, device=device)\n",
    "    model_state_dict = model.state_dict()\n",
    "    to_removes = _remove_duplicate_names(model_state_dict, preferred_names=state_dict.keys())\n",
    "    missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ee61a-23fe-430f-b5f0-4a327b874be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aec2eb-0c97-4229-a4df-d47e6c8bd349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5e6df45-32c2-42e4-80f0-4a46d382dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = load_file(os.path.join(ckpt_path, 'model-00001-of-000163.safetensors'), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d3c6b9-f958-49e0-b601-9d8fd50fb3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict=model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912675b-0c07-48d0-8404-377d6d46b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statedict from safe tensor\n",
    "'model.embed_tokens.weight', \n",
    "'model.layers.0.input_layernorm.weight', \n",
    "'model.layers.0.mlp.down_proj.weight', \n",
    "'model.layers.0.mlp.down_proj.weight_scale_inv', \n",
    "'model.layers.0.mlp.gate_proj.weight', \n",
    "'model.layers.0.mlp.gate_proj.weight_scale_inv', \n",
    "'model.layers.0.mlp.up_proj.weight',\n",
    "'model.layers.0.mlp.up_proj.weight_scale_inv', \n",
    "'model.layers.0.post_attention_layernorm.weight', \n",
    "\n",
    "'model.layers.0.self_attn.kv_a_layernorm.weight', \n",
    "'model.layers.0.self_attn.kv_a_proj_with_mqa.weight', \n",
    "'model.layers.0.self_attn.kv_a_proj_with_mqa.weight_scale_inv', \n",
    "'model.layers.0.self_attn.kv_b_proj.weight', \n",
    "'model.layers.0.self_attn.kv_b_proj.weight_scale_inv', \n",
    "\n",
    "'model.layers.0.self_attn.o_proj.weight', \n",
    "'model.layers.0.self_attn.o_proj.weight_scale_inv',\n",
    "\n",
    "'model.layers.0.self_attn.q_a_layernorm.weight', \n",
    "'model.layers.0.self_attn.q_a_proj.weight', \n",
    "'model.layers.0.self_attn.q_a_proj.weight_scale_inv', \n",
    "'model.layers.0.self_attn.q_b_proj.weight', \n",
    "'model.layers.0.self_attn.q_b_proj.weight_scale_inv',  #Hmm not sure where to put these\n",
    "\n",
    "'model.layers.1.input_layernorm.weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c25ee2-1a2d-47d5-9286-966e59b096c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statedict from model -> these names are super different dafuq? Man I hope I'm not missing something super essential\n",
    "'embed.weight', \n",
    "'layers.0.attn.wq_a.weight', \n",
    "'layers.0.attn.q_norm.weight', \n",
    "'layers.0.attn.wq_b.weight', \n",
    "'layers.0.attn.wkv_a.weight', \n",
    "'layers.0.attn.kv_norm.weight', \n",
    "'layers.0.attn.wkv_b.weight', \n",
    "'layers.0.attn.wo.weight', \n",
    "'layers.0.ffn.w1.weight', \n",
    "'layers.0.ffn.w2.weight', \n",
    "'layers.0.ffn.w3.weight', \n",
    "'layers.0.attn_norm.weight', \n",
    "'layers.0.ffn_norm.weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a99269e2-594d-40a3-b201-ff9d516c2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok this seems sketchy -> I'm kinda having to guess which thing is which -> maybe i try from scratch using\n",
    "# hf repo? Does seem to be sortof working, let me push a little further and fall back to that if needed\n",
    "my_state_dict={}\n",
    "my_state_dict['embed.weight']=state_dict['model.embed_tokens.weight']\n",
    "my_state_dict['layers.0.attn.wq_a.weight']=state_dict['model.layers.0.self_attn.q_a_proj.weight']\n",
    "my_state_dict['layers.0.attn.q_norm.weight']=state_dict['model.layers.0.self_attn.q_a_layernorm.weight']\n",
    "my_state_dict['layers.0.attn.wq_b.weight']=state_dict['model.layers.0.self_attn.q_b_proj.weight']\n",
    "\n",
    "my_state_dict['layers.0.attn.wkv_a.weight'] =state_dict['model.layers.0.self_attn.kv_a_layernorm.weight']\n",
    "my_state_dict['layers.0.attn.kv_norm.weight'] =state_dict['model.layers.0.self_attn.kv_a_layernorm.weight']\n",
    "my_state_dict['layers.0.attn.wkv_b.weight'] =state_dict['model.layers.0.self_attn.kv_b_proj.weight']\n",
    "my_state_dict['layers.0.attn.wo.weight'] =state_dict['model.layers.0.self_attn.o_proj.weight']\n",
    "\n",
    "# my_state_dict['layers.0.ffn.w1.weight'] =state_dict[]\n",
    "# my_state_dict['layers.0.ffn.w2.weight'] =state_dict[]\n",
    "# my_state_dict['layers.0.ffn.w3.weight'] =state_dict[]\n",
    "# my_state_dict['layers.0.attn_norm.weight'] =state_dict[]\n",
    "# my_state_dict['layers.0.ffn_norm.weight']=state_dict[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5df3e4-27e0-4d94-88af-4395f4637fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0464bef-bcb1-4782-9e27-e9f8e1b4623f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc1004-4d5a-4fc9-a116-7a911cd0c715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51aff734-904a-4085-9f80-d4c160dcf1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfcd895c-e9d7-4248-a2ec-b1321f85c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "855f6e63-8eb5-4d60-9875-de94ff882b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fbe6f73-1b68-437d-a938-e85bed36e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict['model.embed_tokens.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39a7b6b9-9952-429c-8d88-bc260c6fcd25",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Transformer:\n\tsize mismatch for layers.0.attn.wkv_a.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576, 7168]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# missing, unexpected = model.load_state_dict(state_dict, strict=False) #, assign=True)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m missing, unexpected \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/deepseek/lib/python3.10/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Transformer:\n\tsize mismatch for layers.0.attn.wkv_a.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([576, 7168])."
     ]
    }
   ],
   "source": [
    "# missing, unexpected = model.load_state_dict(state_dict, strict=False) #, assign=True)\n",
    "missing, unexpected = model.load_state_dict(my_state_dict, strict=False) #, assign=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e45b73aa-da69-48fb-967d-9984d6aaea46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45392"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f93d3450-f8c3-4340-81f2-8f1ae8ccd6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unexpected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ac54c47-dc7f-48aa-9d9e-59c527cd8094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelEmbedding()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb1dae1d-d751-4182-b1b6-74e91bd57223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a90b89-618b-440d-9254-5c5ee8836112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ea8c8-351a-4eda-9c4d-ae8a1a5bb09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f4dd01-ee99-46d5-bdc9-cb025c8d4ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b7cdd7-7848-418c-ba71-cd45aa78f35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54b8bd0-a724-487c-af53-82abefb0af45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45395"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddd88aa5-b195-42d2-9bcf-fda72c56bb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unexpected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "820114c3-1659-414f-a8a1-ae6a0ceb51fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].attn.wq_a.weight.detach().abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2ff7d62-193b-4db2-80de-a13d5443e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.layers[6].attn.kv_a_layernorm.weight\n",
    "# plt.imshow(model.embed.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e415d39f-54d3-47cb-b73f-45a81d34be8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7d519157e770>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ce96cf3-cd7e-4aa7-8e65-8960db20a7eb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3deb73ac-257b-4065-bc7f-5712b6067e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('/home/stephen/deepseek/DeepSeek-V3/DeepSeek-V3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84084276-22ef-436d-8640-77f9f31143d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens=tokenizer.encode(\"The American flag is red, white, and\")\n",
    "model.forward(torch.tensor([tokens]), start_pos=0) #Dope! Ran on CPU somehow - took a couple minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a015306-4831-46bd-b42b-ba2795b33d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536, 7168])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Do I have non-zero weights now?\n",
    "model.layers[0].attn.wq_a.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72ace851-36bd-4360-8120-8ea33950c00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.bfloat16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[6].attn.wq_a.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c20a5-7bf8-4622-8c9b-192afc602db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f61f2d85-9541-4bb0-be68-acb313461c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10, torch.Size([10, 32]), torch.Size([10, 10]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_pos=0 #might need to noodle with this to understad caching\n",
    "seqlen = torch.tensor([tokens]).size(1)\n",
    "freqs_cis = model.freqs_cis[start_pos:start_pos+seqlen]\n",
    "\n",
    "mask = None\n",
    "if seqlen > 1:\n",
    "    mask = torch.full((seqlen, seqlen), float(\"-inf\"), device='cpu').triu_(1) #CPUing for now\n",
    "\n",
    "start_pos, seqlen, freqs_cis.shape, mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af8dc182-9a9e-421c-a8bb-9889db4670f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.embed(torch.tensor([tokens]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a06865-ae1e-4105-858a-a79fa4419ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out=model.layers[0].attn.forward(h, start_pos, freqs_cis, mask) #Run MLA forward pass from outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7e64de8-60be-463a-b278-a73e3c8ed542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 7168])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09dbc3-8a13-4de7-9b81-19b19ea75e25",
   "metadata": {},
   "source": [
    "### Now Set Through Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b37f56f-eae9-47a5-a4d1-7dffa154a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=h\n",
    "mla=model.layers[0].attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ea7fc1a-a099-46f5-bcbe-9f501464dac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hay\n"
     ]
    }
   ],
   "source": [
    "bsz, seqlen, _ = x.size()\n",
    "end_pos = start_pos + seqlen\n",
    "if mla.q_lora_rank == 0:\n",
    "    q = self.wq(x)\n",
    "else:\n",
    "    q = mla.wq_b(mla.q_norm(mla.wq_a(x)))\n",
    "    print('hay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40b04b3-1970-4370-b747-cd0811bd64b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query compression - probably not in script\n",
    "h1=mla.wq_a(x)\n",
    "h2=mla.q_norm(mla.wq_a(x))\n",
    "q=mla.wq_b(mla.q_norm(mla.wq_a(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad37cd7-a1e4-4841-b283-367fc2a1db34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 7168]),\n",
       " torch.Size([1, 10, 1536]),\n",
       " torch.Size([1, 10, 1536]),\n",
       " torch.Size([1, 10, 24576]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, h1.shape, h2.shape, q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "764ff5af-b4cb-4760-8dd3-cd85cfaf0558",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = q.view(bsz, seqlen, mla.n_local_heads, mla.qk_head_dim) #Ok splitting out the queries across all the heads\n",
    "q_nope, q_pe = torch.split(q, [mla.qk_nope_head_dim, mla.qk_rope_head_dim], dim=-1) #Splitting queries into positional embeddings \n",
    "q_pe = apply_rotary_emb(q_pe, freqs_cis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad7647db-834c-4c3c-8f50-33a48489d425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 128, 192]),\n",
       " torch.Size([1, 10, 128, 128]),\n",
       " torch.Size([1, 10, 128, 64]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape, q_nope.shape, q_pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0899f8-5ae0-4a13-a0e7-9862ada27658",
   "metadata": {},
   "source": [
    "Ok, this is not that different from GPT-2, for each of our 128 heads, we haev a 10x128 query vector - got it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1966e58-7d0d-47a9-819c-3b0f4b287765",
   "metadata": {},
   "outputs": [],
   "source": [
    "kv = mla.wkv_a(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33afbf18-7e43-4e7b-bce8-85159eccb3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 10, 7168]), torch.Size([1, 10, 576]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, kv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f4fae9-32c9-4439-a1a1-f91b3f2a837a",
   "metadata": {},
   "source": [
    "- Ok how does this compare to GPT-2 style?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00869a66-165c-4b70-936d-334cffab1ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d1fd4a-f7a7-4f96-97c3-27c4a7f167e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9735458-2cff-4ecd-a6eb-8b3da9c3cd87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039e413-5b0d-4136-9168-12aa58948831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38efe42a-770d-4de5-8281-1b8b9a19ce1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faaec7d-00cc-4d86-9e41-db085bcdf170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459ac62-8280-4acd-9385-04c5f0b22abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
